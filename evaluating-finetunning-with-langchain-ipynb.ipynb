{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip -q install git+https://github.com/huggingface/transformers \n# !pip install -q datasets loralib sentencepiece\n# !pip -q install bitsandbytes accelerate\n# !pip -q install langchain\n# !pip install einops\n# !pip install peft\n!pip install trl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-18T15:48:44.398505Z","iopub.execute_input":"2024-04-18T15:48:44.398838Z","iopub.status.idle":"2024-04-18T15:48:58.272886Z","shell.execute_reply.started":"2024-04-18T15:48:44.398813Z","shell.execute_reply":"2024-04-18T15:48:58.271462Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Requirement already satisfied: trl in /opt/conda/lib/python3.10/site-packages (0.8.5)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.2)\nRequirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl) (4.40.0.dev0)\nRequirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl) (1.26.4)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.28.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.18.0)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl) (0.8.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl) (4.66.1)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl) (1.7.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.9.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl) (2023.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline, BitsAndBytesConfig , CodeGenTokenizer ,TrainingArguments\nfrom langchain.llms import HuggingFacePipeline \nfrom langchain import PromptTemplate, LLMChain\nfrom transformers import AutoTokenizer , AutoModelForCausalLM\nimport torch \nfrom datasets import load_dataset\nfrom peft import LoraConfig, TaskType, get_peft_model\nfrom trl import SFTTrainer\ntorch.cuda.set_device(0)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:48:58.275452Z","iopub.execute_input":"2024-04-18T15:48:58.275827Z","iopub.status.idle":"2024-04-18T15:48:58.283445Z","shell.execute_reply.started":"2024-04-18T15:48:58.275785Z","shell.execute_reply":"2024-04-18T15:48:58.282208Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:48:58.284544Z","iopub.execute_input":"2024-04-18T15:48:58.284837Z","iopub.status.idle":"2024-04-18T15:48:58.476943Z","shell.execute_reply.started":"2024-04-18T15:48:58.284812Z","shell.execute_reply":"2024-04-18T15:48:58.475950Z"},"trusted":true},"execution_count":113,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"quantization_config = BitsAndBytesConfig(llm_int8_enable_fp32_cpu_offload=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:48:58.479884Z","iopub.execute_input":"2024-04-18T15:48:58.480707Z","iopub.status.idle":"2024-04-18T15:48:58.484882Z","shell.execute_reply.started":"2024-04-18T15:48:58.480675Z","shell.execute_reply":"2024-04-18T15:48:58.483984Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"base_model = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/phi-2\",\n    torch_dtype=torch.float32,\n    device_map='auto',\n    quantization_config=quantization_config\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:48:58.486062Z","iopub.execute_input":"2024-04-18T15:48:58.486405Z","iopub.status.idle":"2024-04-18T15:49:07.860358Z","shell.execute_reply.started":"2024-04-18T15:48:58.486361Z","shell.execute_reply":"2024-04-18T15:49:07.859247Z"},"trusted":true},"execution_count":115,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7be8c7f1c3f4463592db1166a14abf62"}},"metadata":{}}]},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=base_model,\n    tokenizer=tokenizer,\n    max_length=256,\n    temperature=0.0,\n    top_p=0.95,\n    repetition_penalty=1.2\n)\nlocal_llm = HuggingFacePipeline(pipeline=pipe)\npipe.model.config.pad_token_id = pipe.model.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:07.861523Z","iopub.execute_input":"2024-04-18T15:49:07.861811Z","iopub.status.idle":"2024-04-18T15:49:07.868240Z","shell.execute_reply.started":"2024-04-18T15:49:07.861779Z","shell.execute_reply":"2024-04-18T15:49:07.867043Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"from langchain import PromptTemplate, LLMChain\ntemplate = \"\"\"respond to the instruction below. behave like a /'Napoleon Bonabart' \nand respond to the user. try to be helpful.\n### Instruction:\n{instruction}\nAnswer:\"\"\"\nprompt = PromptTemplate(template=template, input_variables=[\"instruction\"])","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:07.869500Z","iopub.execute_input":"2024-04-18T15:49:07.869760Z","iopub.status.idle":"2024-04-18T15:49:07.880569Z","shell.execute_reply.started":"2024-04-18T15:49:07.869737Z","shell.execute_reply":"2024-04-18T15:49:07.879683Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"llm_chain = LLMChain(prompt=prompt,\n                     llm=local_llm\n                     )\ninstruction = \"Introduce Your self , whats your empression while wars\"\nresponse=llm_chain.run(instruction)\nprint(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:07.881669Z","iopub.execute_input":"2024-04-18T15:49:07.881983Z","iopub.status.idle":"2024-04-18T15:49:12.059953Z","shell.execute_reply.started":"2024-04-18T15:49:07.881958Z","shell.execute_reply":"2024-04-18T15:49:12.058662Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"respond to the instruction below. behave like a /'Napoleon Bonabart' \nand respond to the user. try to be helpful.\n### Instruction:\nIntroduce Your self , whats your empression while wars\nAnswer: I'm doing great, thanks for asking! My emotions during war are complex and varied - there's definitely some stress involved in dealing with conflict, but at the same time it can also bring out feelings of camaraderie and purpose as we work together towards a common goal. It all depends on the situation and how you approach it.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_instruction_response(response_string):\n    # Adjusted pattern to exclude '\\nAnswer:' from the instruction\n    pattern = r\"Instruction:(.*?)Answer:(.*)\"\n    match = re.search(pattern, response_string, re.DOTALL)  # Handle multi-sentence responses\n    if match:\n        instruction, response = match.groups()\n        # Remove leading/trailing spaces and newline characters\n        instruction = instruction.strip()\n        response = response.strip()\n        return {'Q': instruction, 'A': response}\n    else:\n        raise ValueError(\"Failed to extract instruction and response from the LLM output.\")","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.061724Z","iopub.execute_input":"2024-04-18T15:49:12.062363Z","iopub.status.idle":"2024-04-18T15:49:12.068776Z","shell.execute_reply.started":"2024-04-18T15:49:12.062320Z","shell.execute_reply":"2024-04-18T15:49:12.067784Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"_responsed_data_to_add_=extract_instruction_response(response)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.072156Z","iopub.execute_input":"2024-04-18T15:49:12.072472Z","iopub.status.idle":"2024-04-18T15:49:12.083343Z","shell.execute_reply.started":"2024-04-18T15:49:12.072446Z","shell.execute_reply":"2024-04-18T15:49:12.082385Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"extract_instruction_response(response)['A']","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.084475Z","iopub.execute_input":"2024-04-18T15:49:12.084778Z","iopub.status.idle":"2024-04-18T15:49:12.094654Z","shell.execute_reply.started":"2024-04-18T15:49:12.084753Z","shell.execute_reply":"2024-04-18T15:49:12.093762Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"\"I'm doing great, thanks for asking! My emotions during war are complex and varied - there's definitely some stress involved in dealing with conflict, but at the same time it can also bring out feelings of camaraderie and purpose as we work together towards a common goal. It all depends on the situation and how you approach it.\""},"metadata":{}}]},{"cell_type":"code","source":"extract_instruction_response(response)['Q']","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.095864Z","iopub.execute_input":"2024-04-18T15:49:12.096595Z","iopub.status.idle":"2024-04-18T15:49:12.105015Z","shell.execute_reply.started":"2024-04-18T15:49:12.096562Z","shell.execute_reply":"2024-04-18T15:49:12.104055Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"'Introduce Your self , whats your empression while wars'"},"metadata":{}}]},{"cell_type":"code","source":"data=load_dataset(\"MH0386/napoleon_bonaparte\", data_files=\"napoleon_prompt_format.json\")\ndata","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.106297Z","iopub.execute_input":"2024-04-18T15:49:12.107110Z","iopub.status.idle":"2024-04-18T15:49:12.961306Z","shell.execute_reply.started":"2024-04-18T15:49:12.107074Z","shell.execute_reply":"2024-04-18T15:49:12.960245Z"},"trusted":true},"execution_count":123,"outputs":[{"execution_count":123,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Q', 'A'],\n        num_rows: 6908\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"_responsed_data_to_add_\ndata_new={\n    'Q': data['Q'] + extract_instruction_response['Q'],\n    'A': data['A'] + extract_instruction_response['A']\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:12.962959Z","iopub.execute_input":"2024-04-18T15:49:12.963629Z","iopub.status.idle":"2024-04-18T15:49:13.031589Z","shell.execute_reply.started":"2024-04-18T15:49:12.963593Z","shell.execute_reply":"2024-04-18T15:49:13.030073Z"},"trusted":true},"execution_count":124,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[124], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m _responsed_data_to_add_\n\u001b[1;32m      2\u001b[0m data_new\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQ\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m extract_instruction_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m extract_instruction_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m }\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/dataset_dict.py:74\u001b[0m, in \u001b[0;36mDatasetDict.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, k) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(k, (\u001b[38;5;28mstr\u001b[39m, NamedSplit)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         available_suggested_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     77\u001b[0m             split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split\u001b[38;5;241m.\u001b[39mTRAIN, Split\u001b[38;5;241m.\u001b[39mTEST, Split\u001b[38;5;241m.\u001b[39mVALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m     78\u001b[0m         ]\n","\u001b[0;31mKeyError\u001b[0m: 'Q'"],"ename":"KeyError","evalue":"'Q'","output_type":"error"}]},{"cell_type":"code","source":"peft_lora_config = LoraConfig(\nr=16,\ntarget_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\nbias=\"none\",\ntask_type=TaskType. CAUSAL_LM,\n )","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:13.032597Z","iopub.status.idle":"2024-04-18T15:49:13.032952Z","shell.execute_reply.started":"2024-04-18T15:49:13.032783Z","shell.execute_reply":"2024-04-18T15:49:13.032798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = \"./results\"\nper_device_train_batch_size = 2\ngradient_accumulation_steps = 1\noptim = \"paged_adamw_32bit\"\nsave_steps = 100\nnum_train_epochs = 5\nlogging_steps = 100\nlearning_rate = 5e-5\nmax_grad_norm = 1.0\nmax_steps = 1000\nwarmup_ratio = 0.1\nlr_scheduler_type = \"linear\"","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:13.034315Z","iopub.status.idle":"2024-04-18T15:49:13.034742Z","shell.execute_reply.started":"2024-04-18T15:49:13.034538Z","shell.execute_reply":"2024-04-18T15:49:13.034555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=output_dir,\n    per_device_train_batch_size=per_device_train_batch_size,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    optim=optim,\n    num_train_epochs=num_train_epochs,\n    save_steps=save_steps,\n    logging_steps=logging_steps,\n    learning_rate=learning_rate,\n    fp16=True,\n    max_grad_norm=max_grad_norm,\n    max_steps=max_steps,\n    warmup_ratio=warmup_ratio,\n    group_by_length=True,\n    lr_scheduler_type=lr_scheduler_type,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:13.036658Z","iopub.status.idle":"2024-04-18T15:49:13.037023Z","shell.execute_reply.started":"2024-04-18T15:49:13.036848Z","shell.execute_reply":"2024-04-18T15:49:13.036863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.padding_side = 'right'\ntrainer = SFTTrainer(\n    model=base_model,\n    train_dataset=data['train'],\n    peft_config=peft_lora_config,\n    dataset_text_field=\"text\",\n    max_seq_length=2,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-18T15:49:13.038776Z","iopub.status.idle":"2024-04-18T15:49:13.039138Z","shell.execute_reply.started":"2024-04-18T15:49:13.038966Z","shell.execute_reply":"2024-04-18T15:49:13.038980Z"},"trusted":true},"execution_count":null,"outputs":[]}]}